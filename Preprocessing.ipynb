{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b5cb63-d621-4dbc-bd7e-3c7e663ff135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1754155 entries, 0 to 1754154\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   Unnamed: 0         int64  \n",
      " 1   TRANSACTION_ID     int64  \n",
      " 2   TX_DATETIME        object \n",
      " 3   CUSTOMER_ID        int64  \n",
      " 4   TERMINAL_ID        int64  \n",
      " 5   TX_AMOUNT          float64\n",
      " 6   TX_TIME_SECONDS    int64  \n",
      " 7   TX_TIME_DAYS       int64  \n",
      " 8   TX_FRAUD           int64  \n",
      " 9   TX_FRAUD_SCENARIO  int64  \n",
      "dtypes: float64(1), int64(8), object(1)\n",
      "memory usage: 133.8+ MB\n",
      "None\n",
      "         Unnamed: 0  TRANSACTION_ID   CUSTOMER_ID   TERMINAL_ID     TX_AMOUNT  \\\n",
      "count  1.754155e+06    1.754155e+06  1.754155e+06  1.754155e+06  1.754155e+06   \n",
      "mean   8.770770e+05    8.770770e+05  2.504011e+03  4.996733e+03  5.396820e+02   \n",
      "std    5.063811e+05    5.063811e+05  1.445987e+03  2.886101e+03  1.179711e+03   \n",
      "min    0.000000e+00    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    4.385385e+05    4.385385e+05  1.252000e+03  2.502000e+03  1.799500e+02   \n",
      "50%    8.770770e+05    8.770770e+05  2.506000e+03  4.994000e+03  4.217500e+02   \n",
      "75%    1.315616e+06    1.315616e+06  3.765000e+03  7.495000e+03  7.505950e+02   \n",
      "max    1.754154e+06    1.754154e+06  4.999000e+03  9.999000e+03  6.478375e+05   \n",
      "\n",
      "       TX_TIME_SECONDS  TX_TIME_DAYS      TX_FRAUD  TX_FRAUD_SCENARIO  \n",
      "count     1.754155e+06  1.754155e+06  1.754155e+06       1.754155e+06  \n",
      "mean      7.903234e+06  9.097260e+01  1.345200e-01       1.449746e-01  \n",
      "std       4.565172e+06  5.283709e+01  3.412103e-01       3.874872e-01  \n",
      "min       3.100000e+01  0.000000e+00  0.000000e+00       0.000000e+00  \n",
      "25%       3.940846e+06  4.500000e+01  0.000000e+00       0.000000e+00  \n",
      "50%       7.902670e+06  9.100000e+01  0.000000e+00       0.000000e+00  \n",
      "75%       1.186566e+07  1.370000e+02  0.000000e+00       0.000000e+00  \n",
      "max       1.581120e+07  1.820000e+02  1.000000e+00       3.000000e+00  \n",
      "   Unnamed: 0  TRANSACTION_ID          TX_DATETIME  CUSTOMER_ID  TERMINAL_ID  \\\n",
      "0           0               0  2023-01-01 00:00:31          596         3156   \n",
      "1           1               1  2023-01-01 00:02:10         4961         3412   \n",
      "2           2               2  2023-01-01 00:07:56            2         1365   \n",
      "3           3               3  2023-01-01 00:09:29         4128         8737   \n",
      "4           4               4  2023-01-01 00:10:34          927         9906   \n",
      "\n",
      "   TX_AMOUNT  TX_TIME_SECONDS  TX_TIME_DAYS  TX_FRAUD  TX_FRAUD_SCENARIO  \n",
      "0     533.07               31             0         0                  0  \n",
      "1     808.56              130             0         0                  0  \n",
      "2    1442.94              476             0         1                  1  \n",
      "3     620.65              569             0         0                  0  \n",
      "4     490.66              634             0         0                  0  \n",
      "Training accuracy: 1.0\n",
      "Testing accuracy: 1.0\n",
      "Accuracy on test set: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Load data from CSV file\n",
    "df = pd.read_csv('Final Transactions.csv')\n",
    "\n",
    "# Display basic info about the dataset\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df.head())\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = df.drop(columns=['TRANSACTION_ID', 'TX_DATETIME', 'CUSTOMER_ID', 'TERMINAL_ID', 'TX_AMOUNT', 'TX_TIME_SECONDS', 'TX_TIME_DAYS', 'TX_FRAUD_SCENARIO'])\n",
    "y = df['TX_FRAUD']\n",
    "\n",
    "# Identify numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Apply preprocessing to the data\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Convert the preprocessed data back to a DataFrame to handle z-score calculation easily\n",
    "X_preprocessed_df = pd.DataFrame(X_preprocessed, columns=[f\"num_{i}\" for i in range(X_preprocessed.shape[1])])\n",
    "\n",
    "# Handle outliers using Z-score method\n",
    "z_scores = np.abs(zscore(X_preprocessed_df.select_dtypes(include=[np.float64, np.int64])))\n",
    "X_preprocessed_df = X_preprocessed_df[(z_scores < 3).all(axis=1)]\n",
    "y = y[X_preprocessed_df.index]\n",
    "\n",
    "# Ensure X_preprocessed_df is back to array after handling outliers for further processing\n",
    "X_preprocessed = X_preprocessed_df.to_numpy()\n",
    "\n",
    "# Feature selection: Select top k features, or skip this step if not needed\n",
    "k = min(10, X_preprocessed.shape[1])  # Adjust k to be less than or equal to the number of features\n",
    "selector = SelectKBest(f_classif, k=k)\n",
    "X_selected = selector.fit_transform(X_preprocessed, y)\n",
    "\n",
    "# Apply PCA only if there are enough features\n",
    "if X_selected.shape[1] > 1:  # Proceed with PCA only if there are more than 1 feature\n",
    "    pca_components = min(5, X_selected.shape[1])  # Ensure n_components <= number of features\n",
    "    pca = PCA(n_components=pca_components)\n",
    "    X_pca = pca.fit_transform(X_selected)\n",
    "else:\n",
    "    X_pca = X_selected  # If PCA is not applicable, use the selected features as is\n",
    "\n",
    "# Data augmentation with SMOTE to handle imbalanced dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_pca, y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Decision Tree model (or any other model)\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "\n",
    "print(\"Training accuracy:\", train_score)\n",
    "print(\"Testing accuracy:\", test_score)\n",
    "\n",
    "# Predict and evaluate on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test set:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b837fd-69c7-4664-90d8-8a111766c396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
